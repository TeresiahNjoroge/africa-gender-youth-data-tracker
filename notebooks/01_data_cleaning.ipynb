{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdefad36",
   "metadata": {},
   "source": [
    "# ðŸŒ Africa Gender & Youth Data Tracker\n",
    "## Notebook 01: Data Ingestion, Cleaning & Validation\n",
    "\n",
    "**Author:** Teresiah Njoroge  \n",
    "**Date:** February 2026  \n",
    "**Project:** AU WGYD M&E Data Pipeline  \n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "This notebook ingests raw gender and youth indicator data for 54 African Union \n",
    "member states from the World Bank Open Data API. It performs systematic quality \n",
    "checks, cleans and validates all datasets, and exports analysis-ready files.\n",
    "\n",
    "All data quality decisions are documented inline and in `data_cleaning_log.md`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2c2784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import wbgapi as wb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df43fe0",
   "metadata": {},
   "source": [
    "## Step 1: Set Up Folder Structure\n",
    "\n",
    "We define exact folder paths using absolute paths (full location on disk)\n",
    "to avoid any folder-not-found errors when saving files.\n",
    "\n",
    "- `RAW` â€” where original downloaded files are saved untouched\n",
    "- `CLEAN` â€” where cleaned, analysis-ready files are saved\n",
    "\n",
    "> **Rule:** Always preserve raw data. Never overwrite it.\n",
    "> If cleaning goes wrong, reload from raw without re-downloading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3298955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Notebook location: c:\\Users\\wanji\\AppData\\Local\\Programs\\Microsoft VS Code\n",
      "\n",
      "RAW folder:   c:\\Users\\wanji\\AppData\\Local\\Programs\\Microsoft VS Code\\01_data\\raw\n",
      "CLEAN folder: c:\\Users\\wanji\\AppData\\Local\\Programs\\Microsoft VS Code\\01_data\\cleaned\n",
      "\n",
      "RAW exists:   True\n",
      "CLEAN exists: True\n"
     ]
    }
   ],
   "source": [
    "# Get exact location of this notebook on your computer\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Build full absolute paths\n",
    "RAW   = os.path.join(notebook_dir, '01_data', 'raw')\n",
    "CLEAN = os.path.join(notebook_dir, '01_data', 'cleaned')\n",
    "\n",
    "# Create folders on disk (exist_ok=True means no error if already exists)\n",
    "os.makedirs(RAW,   exist_ok=True)\n",
    "os.makedirs(CLEAN, exist_ok=True)\n",
    "\n",
    "# Confirm\n",
    "print(\"ðŸ“ Notebook location:\", notebook_dir)\n",
    "print()\n",
    "print(\"RAW folder:  \", RAW)\n",
    "print(\"CLEAN folder:\", CLEAN)\n",
    "print()\n",
    "print(\"RAW exists:  \", os.path.isdir(RAW))\n",
    "print(\"CLEAN exists:\", os.path.isdir(CLEAN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2310b1c",
   "metadata": {},
   "source": [
    "## Step 2: Download Raw Data from World Bank API\n",
    "\n",
    "We pull 5 gender and youth indicators for all 54 AU member states\n",
    "covering **2015â€“2023**, aligned with AU Agenda 2063 monitoring targets.\n",
    "\n",
    "| Indicator Code | Description |\n",
    "|---|---|\n",
    "| SL.TLF.ACTI.FE.ZS | Female Labour Force Participation Rate (%) |\n",
    "| SG.GEN.PARL.ZS | Women in National Parliament (%) |\n",
    "| SE.SEC.ENRR.FE | Girls' Secondary School Enrolment (%) |\n",
    "| SL.UEM.1524.FE.ZS | Female Youth Unemployment Rate 15â€“24 (%) |\n",
    "| SL.UEM.1524.MA.ZS | Male Youth Unemployment Rate 15â€“24 (%) |\n",
    "\n",
    "All datasets are stored in `raw_frames` (a Python dictionary in memory)\n",
    "AND saved as CSV files to `01_data/raw/` for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb826e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading female_lfp...\n",
      "  âœ… Shape: (54, 10)\n",
      "Downloading women_in_parliament...\n",
      "  âœ… Shape: (54, 10)\n",
      "Downloading girls_secondary_enrol...\n",
      "  âœ… Shape: (54, 10)\n",
      "Downloading youth_unemployment_f...\n",
      "  âœ… Shape: (54, 10)\n",
      "Downloading youth_unemployment_m...\n",
      "  âœ… Shape: (54, 10)\n",
      "\n",
      "âœ… raw_frames contains: ['female_lfp', 'women_in_parliament', 'girls_secondary_enrol', 'youth_unemployment_f', 'youth_unemployment_m']\n"
     ]
    }
   ],
   "source": [
    "indicators = {\n",
    "    'SL.TLF.ACTI.FE.ZS': 'female_lfp',\n",
    "    'SG.GEN.PARL.ZS':     'women_in_parliament',\n",
    "    'SE.SEC.ENRR.FE':     'girls_secondary_enrol',\n",
    "    'SL.UEM.1524.FE.ZS':  'youth_unemployment_f',\n",
    "    'SL.UEM.1524.MA.ZS':  'youth_unemployment_m',\n",
    "}\n",
    "\n",
    "africa = wb.region.members('AFR')\n",
    "raw_frames = {}\n",
    "\n",
    "for code, name in indicators.items():\n",
    "    print(f\"Downloading {name}...\")\n",
    "    df = wb.data.DataFrame(code,\n",
    "                            economy=africa,\n",
    "                            time=range(2015, 2024))\n",
    "    df.reset_index(inplace=True)\n",
    "    raw_frames[name] = df\n",
    "    print(f\"  âœ… Shape: {df.shape}\")\n",
    "\n",
    "print()\n",
    "print(\"âœ… raw_frames contains:\", list(raw_frames.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22a498",
   "metadata": {},
   "source": [
    "## Step 3: Save Raw Files to Disk\n",
    "\n",
    "We save each downloaded dataset as a CSV file **before any cleaning begins**.\n",
    "\n",
    "> **Why save raw files?**  \n",
    "> This is standard data practice â€” always preserve the original untouched data.  \n",
    "> If cleaning goes wrong at any point, you can reload from raw  \n",
    "> without having to re-download from the internet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1261382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: female_lfp.csv\n",
      "âœ… Saved: women_in_parliament.csv\n",
      "âœ… Saved: girls_secondary_enrol.csv\n",
      "âœ… Saved: youth_unemployment_f.csv\n",
      "âœ… Saved: youth_unemployment_m.csv\n",
      "\n",
      "ðŸ“‚ Files now in RAW folder:\n",
      "   female_lfp.csv\n",
      "   girls_secondary_enrol.csv\n",
      "   women_in_parliament.csv\n",
      "   youth_unemployment_f.csv\n",
      "   youth_unemployment_m.csv\n"
     ]
    }
   ],
   "source": [
    "for name, df in raw_frames.items():\n",
    "    save_path = os.path.join(RAW, f'{name}.csv')\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"âœ… Saved: {name}.csv\")\n",
    "\n",
    "print()\n",
    "print(\"ðŸ“‚ Files now in RAW folder:\")\n",
    "for f in os.listdir(RAW):\n",
    "    print(f\"   {f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f5dd19",
   "metadata": {},
   "source": [
    "## Step 4: Data Quality Assessment\n",
    "\n",
    "Before cleaning anything, we run a quality check on every raw dataset.\n",
    "We check for 4 things:\n",
    "\n",
    "| Check | Question we are asking |\n",
    "|---|---|\n",
    "| **Shape** | How many rows and columns does this dataset have? |\n",
    "| **Missing values** | How many empty cells are there in total? |\n",
    "| **Duplicates** | Are any rows repeated exactly? |\n",
    "| **Countries** | How many unique countries are included? |\n",
    "\n",
    "This step tells us **what problems exist** before we fix them.  \n",
    "We expect 54 countries per indicator (all AU member states).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63481ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DATASET: female_lfp\n",
      "  Shape:          (54, 10)\n",
      "  Missing values: 10 total cells\n",
      "  Duplicate rows: 0\n",
      "  Countries:      54\n",
      "\n",
      "==================================================\n",
      "DATASET: women_in_parliament\n",
      "  Shape:          (54, 10)\n",
      "  Missing values: 16 total cells\n",
      "  Duplicate rows: 0\n",
      "  Countries:      54\n",
      "\n",
      "==================================================\n",
      "DATASET: girls_secondary_enrol\n",
      "  Shape:          (54, 10)\n",
      "  Missing values: 270 total cells\n",
      "  Duplicate rows: 0\n",
      "  Countries:      54\n",
      "\n",
      "==================================================\n",
      "DATASET: youth_unemployment_f\n",
      "  Shape:          (54, 10)\n",
      "  Missing values: 10 total cells\n",
      "  Duplicate rows: 0\n",
      "  Countries:      54\n",
      "\n",
      "==================================================\n",
      "DATASET: youth_unemployment_m\n",
      "  Shape:          (54, 10)\n",
      "  Missing values: 10 total cells\n",
      "  Duplicate rows: 0\n",
      "  Countries:      54\n",
      "\n",
      "==================================================\n",
      "âœ… Quality check complete\n"
     ]
    }
   ],
   "source": [
    "def quality_report(df, name):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"DATASET: {name}\")\n",
    "    print(f\"  Shape:          {df.shape}\")\n",
    "    print(f\"  Missing values: {df.isnull().sum().sum()} total cells\")\n",
    "    print(f\"  Duplicate rows: {df.duplicated().sum()}\")\n",
    "    if 'economy' in df.columns:\n",
    "        print(f\"  Countries:      {df['economy'].nunique()}\")\n",
    "\n",
    "for name, df in raw_frames.items():\n",
    "    quality_report(df, name)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"âœ… Quality check complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105795cd",
   "metadata": {},
   "source": [
    "## Step 5: Data Cleaning & Standardisation\n",
    "\n",
    "We apply 8 cleaning steps to every dataset:\n",
    "\n",
    "| Step | Action | Reason |\n",
    "|---|---|---|\n",
    "| 1 | Identify year vs non-year columns | Separate data from metadata |\n",
    "| 2 | Reshape wide â†’ long format | One row per country per year (tidy data) |\n",
    "| 3 | Clean year column | Extract 4-digit year from formats like `YR2015` |\n",
    "| 4 | Rename `economy` â†’ `country_code` | Standardise column naming |\n",
    "| 5 | Add AU region | Enable regional comparisons |\n",
    "| 6 | Add `quality_flag` | Mark MISSING vs VERIFIED â€” never silently drop data |\n",
    "| 7 | Add indicator name | Identify which indicator each row belongs to |\n",
    "| 8 | Remove duplicates | One record per country per year only |\n",
    "\n",
    "> **Key decision:** Missing values are FLAGGED, not deleted or imputed.  \n",
    "> This is standard M&E practice â€” gaps must be visible in reports,  \n",
    "> not hidden by automatic substitution.\n",
    "\n",
    "> **Notable finding from quality check:**  \n",
    "> `girls_secondary_enrol` has 270 missing cells â€” this will be  \n",
    "> flagged in the data cleaning log and reported to stakeholders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ecbd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… clean_dataset function defined â€” ready to run\n"
     ]
    }
   ],
   "source": [
    "au_regions = {\n",
    "    'KEN':'East Africa','ETH':'East Africa','TZA':'East Africa',\n",
    "    'UGA':'East Africa','RWA':'East Africa','BDI':'East Africa',\n",
    "    'SOM':'East Africa','DJI':'East Africa','ERI':'East Africa',\n",
    "    'SSD':'East Africa','MDG':'East Africa','COM':'East Africa',\n",
    "    'MUS':'East Africa','SYC':'East Africa',\n",
    "    'NGA':'West Africa','GHA':'West Africa','SEN':'West Africa',\n",
    "    'CIV':'West Africa','MLI':'West Africa','BFA':'West Africa',\n",
    "    'NER':'West Africa','GIN':'West Africa','SLE':'West Africa',\n",
    "    'LBR':'West Africa','MRT':'West Africa','GMB':'West Africa',\n",
    "    'GNB':'West Africa','CPV':'West Africa','TGO':'West Africa',\n",
    "    'BEN':'West Africa',\n",
    "    'ZAF':'Southern Africa','ZWE':'Southern Africa','MOZ':'Southern Africa',\n",
    "    'ZMB':'Southern Africa','MWI':'Southern Africa','BWA':'Southern Africa',\n",
    "    'NAM':'Southern Africa','LSO':'Southern Africa','SWZ':'Southern Africa',\n",
    "    'AGO':'Central Africa','CMR':'Central Africa','COD':'Central Africa',\n",
    "    'COG':'Central Africa','CAF':'Central Africa','TCD':'Central Africa',\n",
    "    'GNQ':'Central Africa','GAB':'Central Africa','STP':'Central Africa',\n",
    "    'EGY':'North Africa','DZA':'North Africa','MAR':'North Africa',\n",
    "    'TUN':'North Africa','LBA':'North Africa','SDN':'North Africa',\n",
    "}\n",
    "\n",
    "def clean_dataset(df, indicator_name):\n",
    "    # Step 1: Identify year columns vs non-year columns\n",
    "    year_cols = [c for c in df.columns\n",
    "                 if str(c).startswith('YR') or\n",
    "                 (str(c).replace('.','').isdigit() and len(str(c)) == 4)]\n",
    "    id_cols = [c for c in df.columns if c not in year_cols]\n",
    "\n",
    "    # Step 2: Reshape wide to long â€” one row per country per year\n",
    "    df_long = df.melt(id_vars=id_cols,\n",
    "                      value_vars=year_cols,\n",
    "                      var_name='year',\n",
    "                      value_name='value')\n",
    "\n",
    "    # Step 3: Clean year column â€” extract 4-digit number\n",
    "    df_long['year'] = df_long['year'].astype(str).str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "    # Step 4: Rename economy to country_code\n",
    "    if 'economy' in df_long.columns:\n",
    "        df_long.rename(columns={'economy': 'country_code'}, inplace=True)\n",
    "\n",
    "    # Step 5: Add AU region\n",
    "    df_long['au_region'] = df_long['country_code'].map(au_regions).fillna('Other')\n",
    "\n",
    "    # Step 6: Add quality flag\n",
    "    df_long['quality_flag'] = np.where(\n",
    "        df_long['value'].isnull(), 'MISSING', 'VERIFIED'\n",
    "    )\n",
    "\n",
    "    # Step 7: Add indicator name\n",
    "    df_long['indicator'] = indicator_name\n",
    "\n",
    "    # Step 8: Remove duplicates\n",
    "    df_long.drop_duplicates(subset=['country_code', 'year'], inplace=True)\n",
    "    df_long.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_long\n",
    "\n",
    "print(\"âœ… clean_dataset function defined â€” ready to run\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ba757",
   "metadata": {},
   "source": [
    "## Step 6: Run Cleaning & Save Cleaned Files\n",
    "\n",
    "We now apply the `clean_dataset` function to all 5 indicators\n",
    "and save the cleaned outputs to `01_data/cleaned/`.\n",
    "\n",
    "After this step each cleaned file will have these columns:\n",
    "\n",
    "| Column | Description |\n",
    "|---|---|\n",
    "| `country_code` | 3-letter ISO country code (e.g. KEN, ETH) |\n",
    "| `year` | 4-digit year (2015â€“2023) |\n",
    "| `value` | Indicator value for that country and year |\n",
    "| `au_region` | AU regional classification |\n",
    "| `quality_flag` | VERIFIED = has data, MISSING = empty cell |\n",
    "| `indicator` | Name of the indicator |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e202b72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning female_lfp...\n",
      "  âœ… Rows: 486 | Verified: 476 | Missing: 10 | Completeness: 97.9%\n",
      "Cleaning women_in_parliament...\n",
      "  âœ… Rows: 486 | Verified: 470 | Missing: 16 | Completeness: 96.7%\n",
      "Cleaning girls_secondary_enrol...\n",
      "  âœ… Rows: 486 | Verified: 216 | Missing: 270 | Completeness: 44.4%\n",
      "Cleaning youth_unemployment_f...\n",
      "  âœ… Rows: 486 | Verified: 476 | Missing: 10 | Completeness: 97.9%\n",
      "Cleaning youth_unemployment_m...\n",
      "  âœ… Rows: 486 | Verified: 476 | Missing: 10 | Completeness: 97.9%\n",
      "\n",
      "ðŸ“‚ Files saved to CLEAN folder:\n",
      "   female_lfp_clean.csv\n",
      "   girls_secondary_enrol_clean.csv\n",
      "   women_in_parliament_clean.csv\n",
      "   youth_unemployment_f_clean.csv\n",
      "   youth_unemployment_m_clean.csv\n",
      "\n",
      "âœ… All datasets cleaned and saved successfully\n"
     ]
    }
   ],
   "source": [
    "cleaned_frames = {}\n",
    "\n",
    "for name, df in raw_frames.items():\n",
    "    print(f\"Cleaning {name}...\")\n",
    "\n",
    "    # Run the cleaning function\n",
    "    cleaned = clean_dataset(df.copy(), name)\n",
    "\n",
    "    # Store in memory\n",
    "    cleaned_frames[name] = cleaned\n",
    "\n",
    "    # Save to cleaned folder using absolute path\n",
    "    save_path = os.path.join(CLEAN, f'{name}_clean.csv')\n",
    "    cleaned.to_csv(save_path, index=False)\n",
    "\n",
    "    # Summary counts\n",
    "    verified = (cleaned['quality_flag'] == 'VERIFIED').sum()\n",
    "    missing  = (cleaned['quality_flag'] == 'MISSING').sum()\n",
    "    total    = len(cleaned)\n",
    "    pct      = round(verified / total * 100, 1)\n",
    "\n",
    "    print(f\"  âœ… Rows: {total} | Verified: {verified} | Missing: {missing} | Completeness: {pct}%\")\n",
    "\n",
    "print()\n",
    "print(\"ðŸ“‚ Files saved to CLEAN folder:\")\n",
    "for f in os.listdir(CLEAN):\n",
    "    print(f\"   {f}\")\n",
    "\n",
    "print()\n",
    "print(\"âœ… All datasets cleaned and saved successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
